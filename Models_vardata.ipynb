{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c6ec5b",
   "metadata": {},
   "source": [
    "This notebook aims to do exactly the same as Basic_models.ipynb did, i.e. try to fit the data given to different models with suitable hyperparameters.\n",
    "However, this time we will transform the data given and see on which of the models it works the best and if it wins \n",
    "with the previous results found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a58a6",
   "metadata": {},
   "source": [
    "### 1. Setting up functions from Basic_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867fe0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rocznik</th>\n",
       "      <th>sesja I</th>\n",
       "      <th>X</th>\n",
       "      <th>XII</th>\n",
       "      <th>sesja II</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>wynik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>77.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>85.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>41.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>78.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rocznik  sesja I     X   XII  sesja II    II   III  wynik\n",
       "0       19     77.0  53.0  63.0      75.0  75.0  61.0     60\n",
       "1       19     85.0  69.0  97.0      93.0  91.0  88.0     93\n",
       "2       19     41.0  31.0  33.0      48.0  66.0  36.0     50\n",
       "3       19     78.0  81.0  83.0      70.0  94.0  91.0     93\n",
       "4       19     26.0  22.0  53.0      25.0  41.0  21.0     27"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from numpy.linalg import inv\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from itertools import chain\n",
    "from scipy.optimize import minimize \n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "df = pd.read_excel('data_clean.xlsx')\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "X = df.iloc[:, 1:7]\n",
    "y = df['wynik']\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd89ae1b",
   "metadata": {},
   "source": [
    "Before we begin there is one thing to bear in mind - we are doing here the same thing as in Basic_models.ipynb but in functions so that we can later transform our data (e.g. using percentiles) and do the same to them.\n",
    "However! We will want to first tranform our original data $X$ into some $X_{mapped}$, then apply our models to them\n",
    "getting predictions $y_{mapped\\_pred}$, then apply the inverse function to get actual predictions $y_{pred}$ on $X$\n",
    "itself so that at the end of the day, we can measure the error and compare to the original one.\n",
    "\n",
    "These are the reasons for additional y_yr_true, type and distr variables in functions - to indicate whether we are dealing with percentile scenario and if so, how should we invert it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24843515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_cv_split(data, X, y):\n",
    "    #initializing cross-val split\n",
    "    params = {} #output\n",
    "    X_yr, y_yr = {}, {} #dev sets of X and y from a given year\n",
    "    X_slice, y_slice = {}, {} #training sets complimentary to X_yr and y_yr\n",
    "    X_slice_trimmed, X_yr_trimmed = {}, {} #the same as above but restricted to the most important columns \n",
    "    X_slice_scaled, X_yr_scaled, X_slice_trimmed_scaled, X_yr_trimmed_scaled = {}, {}, {}, {} #scaled versions\n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    for year in range(19,23):\n",
    "        X_yr[year], y_yr[year] = X[data['rocznik'] == year], y[data['rocznik'] == year]\n",
    "        X_slice[year], y_slice[year] = X[data['rocznik'] != year], y[data['rocznik'] != year]\n",
    "        X_slice_trimmed[year], X_yr_trimmed[year] = X_slice[year].iloc[:,[0,4,5]], X_yr[year].iloc[:,[0,4,5]]\n",
    "        \n",
    "        #scaling normal data\n",
    "        X_slice_scaled[year] = scaler.fit_transform(X_slice[year])\n",
    "        X_yr_scaled[year] = scaler.transform(X_yr[year])\n",
    "        \n",
    "        #scaling trimmed versions\n",
    "        X_slice_trimmed_scaled[year] = scaler.fit_transform(X_slice_trimmed[year])\n",
    "        X_yr_trimmed_scaled[year] = scaler.transform(X_yr_trimmed[year])\n",
    "        \n",
    "    #saving all our data to params dictionary\n",
    "    params['X_yr'], params['y_yr'] = X_yr, y_yr\n",
    "    params['X_slice'], params['y_slice'] = X_slice, y_slice\n",
    "    params['X_slice_trimmed'], params['X_yr_trimmed'] = X_slice_trimmed, X_yr_trimmed\n",
    "    params['X_slice_scaled'], params['X_yr_scaled'], params['X_slice_trimmed_scaled'], params['X_yr_trimmed_scaled'] = \\\n",
    "    X_slice_scaled, X_yr_scaled, X_slice_trimmed_scaled, X_yr_trimmed_scaled\n",
    "    \n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b872812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(lambda_, Ainv, b):   \n",
    "    x = b - lambda_\n",
    "    w = np.dot(Ainv, b-lambda_)\n",
    "    sum_ = np.sum(w.flatten())\n",
    "    J = (sum_ - 1)**2\n",
    "    v = 1000 * np.maximum(0,np.abs(w - 1/2).flatten() - 1/2)\n",
    "    v = v ** 2\n",
    "    J += np.sum(v)\n",
    "    return J\n",
    "\n",
    "def reslinreg(params, mode = 'mse'):\n",
    "    X_slice, y_slice = params['X_slice'], params['y_slice']\n",
    "    X_yr, y_yr = params['X_yr'], params['y_yr']\n",
    "    \n",
    "    err_tr_reslinreg, err_dev_reslinreg = [], []\n",
    "    max_entry = {} \n",
    "\n",
    "    for year in range(19,23):\n",
    "        X_train, y_train = X_slice[year], y_slice[year]\n",
    "        X_dev, y_dev = X_yr[year], y_yr[year]\n",
    "        \n",
    "        A = 2 * np.dot(X_train.T, X_train)\n",
    "        Ainv = inv(A)\n",
    "        b = 2 * np.dot(X_train.T, y_train) # setting Ainv and b to optimize fun()\n",
    "\n",
    "        lambda_ = 1\n",
    "        min_ = minimize(fun, 1, args = (Ainv, b)) #fixing parameters Ainv and b\n",
    "        lambda_ = min_.x\n",
    "\n",
    "        x = b - lambda_\n",
    "        w = np.dot(Ainv, b-lambda_)\n",
    " \n",
    "        y_dev_pred = np.dot(X_yr[year], w)\n",
    "        y_dev_pred = np.minimum(y_dev_pred, 100)\n",
    "        if mode == 'mse':\n",
    "            err_dev_reslinreg.append(mse(y_dev_pred, y_yr[year]))\n",
    "        if mode == 'mae':\n",
    "            err_dev_reslinreg.append(mae(y_dev_pred, y_yr[year]))\n",
    "            \n",
    "    \n",
    "    if mode == 'mse':\n",
    "            outcomes = [int(x) for x in err_dev_reslinreg] + [int(np.max(err_dev_reslinreg))]\n",
    "    if mode == 'mae':\n",
    "        outcomes = [int(x) for x in err_dev_reslinreg] + [int(np.mean(err_dev_reslinreg))]\n",
    "    \n",
    "    return outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4a5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(params, X_true = X.copy(), y_yr_true = {}, type_ = 'normal', distr = {}, mode = 'mse'):\n",
    "    X_slice_scaled, y_slice = params['X_slice_scaled'], params['y_slice']\n",
    "    X_yr_scaled, y_yr = params['X_yr_scaled'], params['y_yr']\n",
    "    \n",
    "    if y_yr_true == {}:\n",
    "        y_yr_true = y_yr.copy()\n",
    "    err_tr_linreg, err_dev_linreg = [], []\n",
    "\n",
    "    for year in range(19,23):\n",
    "        X_train, y_train = X_slice_scaled[year], y_slice[year]\n",
    "        X_dev, y_dev = X_yr_scaled[year], y_yr[year]    \n",
    "\n",
    "        linreg = LinearRegression()\n",
    "        linreg.fit(X_train, y_train)\n",
    "        \n",
    "        y_dev_pred = np.minimum(linreg.predict(X_dev), 100)\n",
    "        \n",
    "        if type_ == 'perc':\n",
    "            y_dev = y_yr_true[year]\n",
    "            y_dev_pred = 100 * stats.scoreatpercentile(distr[year], y_dev_pred)    \n",
    "            \n",
    "        if mode == 'mse':\n",
    "            err_dev_linreg.append(mse(y_dev_pred, y_yr[year]))\n",
    "        if mode == 'mae':\n",
    "            err_dev_linreg.append(mae(y_dev_pred, y_yr[year]))\n",
    "            \n",
    "    \n",
    "    if mode == 'mse':\n",
    "            outcomes = [int(x) for x in err_dev_linreg] + [int(np.max(err_dev_linreg))]\n",
    "    if mode == 'mae':\n",
    "        outcomes = [int(x) for x in err_dev_linreg] + [int(np.mean(err_dev_linreg))]\n",
    "    return outcomes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cdf70be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_tree(params, y_yr_true = {}, type_ = 'normal', distr = {}, \n",
    "              max_depth_best = 0, min_samples_leaf_best = 0, mode = 'mse'):\n",
    "    X_slice, y_slice = params['X_slice'], params['y_slice']\n",
    "    X_yr, y_yr = params['X_yr'], params['y_yr']    \n",
    "    \n",
    "    if y_yr_true == {}:\n",
    "        y_yr_true = y_yr.copy()\n",
    "    err_dev_max_best = 10000 #best cross-val error, i.e. average over single dev errors\n",
    "    err_dev_best = [] #list of dev errors that give the best average\n",
    "\n",
    "    #finding best params for max_depth and min_samples_leaf\n",
    "    if mode == 'mse':\n",
    "        for max_depth in range(1,6):\n",
    "            for min_samples_leaf in range(1,4):\n",
    "                tree = DecisionTreeRegressor(max_depth = max_depth, min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "                err_train_temp = []\n",
    "                err_dev_temp = []\n",
    "\n",
    "                for year in range(19,23):\n",
    "                    X_train = X_slice[year]\n",
    "                    y_train = y_slice[year]\n",
    "                    X_dev = X_yr[year]\n",
    "                    y_dev = y_yr[year]\n",
    "\n",
    "                    tree.fit(X_train, y_train)\n",
    "                    y_dev_pred = tree.predict(X_dev)\n",
    "\n",
    "                    if type_ == 'perc':\n",
    "                        y_dev = y_yr_true[year]\n",
    "                        y_dev_pred = 100 * stats.scoreatpercentile(distr[year], y_dev_pred)                    \n",
    "\n",
    "                    err_dev_temp.append(mse(y_dev_pred, y_dev))\n",
    "\n",
    "                err_dev_max_temp = np.max(err_dev_temp)\n",
    "\n",
    "                if err_dev_max_best > err_dev_max_temp:\n",
    "\n",
    "                    err_dev_max_best = err_dev_max_temp\n",
    "                    err_dev_best = err_dev_temp.copy()\n",
    "                    max_depth_best = max_depth\n",
    "                    min_samples_leaf_best = min_samples_leaf\n",
    "    \n",
    "    err_dev_best = []\n",
    "    #finding predictions for the best tree\n",
    "    for year in range(19,23):\n",
    "        tree = DecisionTreeRegressor(max_depth = max_depth_best, min_samples_leaf = min_samples_leaf_best)\n",
    "        X_train = X_slice[year]\n",
    "        y_train = y_slice[year]\n",
    "        X_dev = X_yr[year]\n",
    "        y_dev = y_yr[year]\n",
    "\n",
    "        tree.fit(X_train, y_train)\n",
    "        y_dev_pred = tree.predict(X_dev)\n",
    "\n",
    "        if type_ == 'perc':\n",
    "            y_dev = y_yr_true[year]\n",
    "            y_dev_pred = 100 * stats.scoreatpercentile(distr[year], y_dev_pred) \n",
    "            \n",
    "        if mode == 'mse':\n",
    "            err_dev_best.append(mse(y_dev_pred, y_yr[year]))\n",
    "        if mode == 'mae':\n",
    "            err_dev_best.append(mae(y_dev_pred, y_yr[year]))\n",
    "            \n",
    "    \n",
    "    if mode == 'mse':\n",
    "        outcomes = [int(x) for x in err_dev_best] + [int(np.max(err_dev_best))]\n",
    "        print('Best max depth for tree: ' + str(max_depth_best))\n",
    "        print('Best min_samples_leaf for tree: ' + str(min_samples_leaf) + '\\n')\n",
    "    if mode == 'mae':\n",
    "        outcomes = [int(x) for x in err_dev_best] + [int(np.mean(err_dev_best))]\n",
    "        \n",
    "    \n",
    "    \n",
    "    return outcomes, max_depth_best, min_samples_leaf_best\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a7a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting max_depth = 1 to avoid overfitting to dev set\n",
    "def best_forest(params, max_depth = 1, y_yr_true = {}, type_ = 'normal', distr = {}, mode = 'mse'): \n",
    "    \n",
    "    X_slice_trimmed_scaled, y_slice = params['X_slice_trimmed_scaled'], params['y_slice']\n",
    "    X_yr_trimmed_scaled, y_yr = params['X_yr_trimmed_scaled'], params['y_yr']\n",
    "    \n",
    "    \n",
    "    if y_yr_true == {}:\n",
    "        y_yr_true = y_yr.copy()\n",
    "    err_dev_best, err_dev_temp = {}, {}\n",
    "    err_dev_max_best = 10000\n",
    "    max_depth_best = 0\n",
    "    n_estimators_best = 0\n",
    "\n",
    "    for n_estimators in range(1,20):\n",
    "        forest = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, random_state = 42)\n",
    "        for year in range(19,23):\n",
    "            X_train, y_train = X_slice_trimmed_scaled[year], y_slice[year] #selecting only significant cols\n",
    "            X_dev, y_dev = X_yr_trimmed_scaled[year], y_yr[year]   \n",
    "\n",
    "            forest.fit(X_train, y_train)    \n",
    "            y_dev_pred = forest.predict(X_dev)\n",
    "            \n",
    "            if type_ == 'perc':\n",
    "                y_dev = y_yr_true[year]\n",
    "                y_dev_pred = 100 * stats.scoreatpercentile(distr[year], y_dev_pred)  \n",
    "\n",
    "            err_dev_temp[year] = mse(y_dev_pred, y_dev)\n",
    "\n",
    "        err_dev_max_temp = np.max(list(err_dev_temp.values()))\n",
    "        \n",
    "        if err_dev_max_best > err_dev_max_temp:  \n",
    "            \n",
    "            err_dev_max_best = err_dev_max_temp\n",
    "            max_depth_best = max_depth\n",
    "            n_estimators_best = n_estimators\n",
    "            \n",
    "    \n",
    "    forest = RandomForestRegressor(n_estimators = n_estimators_best, max_depth = max_depth, random_state = 24)\n",
    "    for year in range(19,23):\n",
    "        X_train, y_train = X_slice_trimmed_scaled[year], y_slice[year] \n",
    "        X_dev, y_dev = X_yr_trimmed_scaled[year], y_yr[year]   \n",
    "\n",
    "        forest.fit(X_train, y_train)    \n",
    "        y_dev_pred = forest.predict(X_dev)\n",
    "        \n",
    "        if type_ == 'perc':\n",
    "            y_dev = y_yr_true[year]\n",
    "            y_dev_pred = 100 * stats.scoreatpercentile(distr[year], y_dev_pred)  \n",
    "\n",
    "            \n",
    "        if mode == 'mse':\n",
    "            err_dev_best[year] = mse(y_dev_pred, y_dev)\n",
    "        if mode == 'mae':\n",
    "            err_dev_best[year] = mae(y_dev_pred, y_dev)\n",
    "            \n",
    "    \n",
    "    if mode == 'mse':\n",
    "        err_dev_max_best = np.max(list(err_dev_best.values()))\n",
    "        outcomes = [int(x) for x in list(err_dev_best.values())] + [int(err_dev_max_best)]\n",
    "    if mode == 'mae':\n",
    "        err_dev_mean_best = np.mean(list(err_dev_best.values()))\n",
    "        outcomes = [x for x in list(err_dev_best.values())] + [err_dev_mean_best]\n",
    "        \n",
    "\n",
    "    \n",
    "            \n",
    "            \n",
    "    print('Best max depth for forest: ' + str(max_depth_best))\n",
    "    print('Best number of estimators: ' + str(n_estimators_best) + '\\n')\n",
    "    return outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2d8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting max_depth = 1 to avoid overfitting to dev set\n",
    "def best_xgb(params, max_depth = 1, y_yr_true = {}, type_ = 'normal', distr = {}, mode = 'mse'):\n",
    "    \n",
    "    X_slice_trimmed_scaled, y_slice = params['X_slice_trimmed_scaled'], params['y_slice']\n",
    "    X_yr_trimmed_scaled, y_yr = params['X_yr_trimmed_scaled'], params['y_yr']\n",
    "    \n",
    "    if y_yr_true == {}:\n",
    "        y_yr_true = y_yr.copy()\n",
    "    err_dev_best = {}\n",
    "    err_dev_temp = {}\n",
    "    err_dev_max_best = 10000\n",
    "    max_depth_best = 0\n",
    "    n_estimators_best = 0\n",
    "\n",
    "\n",
    "    for n_estimators in range(1,21):\n",
    "        \n",
    "        xgb = XGBRegressor(n_estimators = n_estimators, max_depth = max_depth, random_state = 42)\n",
    "        for year in range(19,23):\n",
    "            X_train, y_train = X_slice_trimmed_scaled[year], y_slice[year] #selecting only significant cols\n",
    "            X_dev, y_dev = X_yr_trimmed_scaled[year], y_yr[year] \n",
    "\n",
    "            xgb.fit(X_train, y_train)    \n",
    "            y_dev_pred = np.minimum(xgb.predict(X_dev), 100)\n",
    "            \n",
    "            if type_ == 'perc':\n",
    "                \n",
    "                y_dev = y_yr_true[year]\n",
    "                y_dev_pred = 100 * stats.scoreatpercentile(distr[year], y_dev_pred)  \n",
    "\n",
    "            err_dev_temp[year] = mse(y_dev_pred, y_dev)\n",
    "\n",
    "        err_dev_max_temp = np.max(list(err_dev_temp.values()))\n",
    "        if err_dev_max_best > err_dev_max_temp:\n",
    "            \n",
    "            err_dev_max_best = err_dev_max_temp\n",
    "            n_estimators_best = n_estimators\n",
    "    \n",
    "    #Running the best n_estimators with different random_state to get less optimistic errors\n",
    "    xgb = XGBRegressor(n_estimators = n_estimators_best, max_depth = max_depth, random_state = 24)\n",
    "    for year in range(19,23):\n",
    "        X_train, y_train = X_slice_trimmed_scaled[year], y_slice[year] \n",
    "        X_dev, y_dev = X_yr_trimmed_scaled[year], y_yr[year]   \n",
    "\n",
    "        xgb.fit(X_train, y_train)    \n",
    "        y_dev_pred = np.minimum(xgb.predict(X_dev), 100)\n",
    "        \n",
    "        if type_ == 'perc':\n",
    "            y_dev = y_yr_true[year]\n",
    "            y_dev_pred = 100 * stats.scoreatpercentile(distr[year], y_dev_pred)  \n",
    "\n",
    "        \n",
    "        if mode == 'mse':\n",
    "            err_dev_best[year] = mse(y_dev_pred, y_dev)\n",
    "        if mode == 'mae':\n",
    "            err_dev_best[year] = mae(y_dev_pred, y_dev)\n",
    "            \n",
    "    \n",
    "    if mode == 'mse':\n",
    "        err_dev_max_best = np.max(list(err_dev_best.values()))\n",
    "        outcomes = [int(x) for x in list(err_dev_best.values())] + [int(err_dev_max_best)]\n",
    "    if mode == 'mae':\n",
    "        err_dev_mean_best = np.mean(list(err_dev_best.values()))\n",
    "        outcomes = [x for x in list(err_dev_best.values())] + [err_dev_mean_best]\n",
    "            \n",
    "    \n",
    "    print('Best max depth for XGBoost: ' + str(max_depth))\n",
    "    print('Best number of estimators: ' + str(n_estimators_best) + '\\n')\n",
    "    return outcomes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286956a3",
   "metadata": {},
   "source": [
    "### 1. Normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d12649e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max depth for tree: 1\n",
      "Best min_samples_leaf for tree: 3\n",
      "\n",
      "Best max depth for forest: 1\n",
      "Best number of estimators: 10\n",
      "\n",
      "Best max depth for XGBoost: 1\n",
      "Best number of estimators: 9\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Restricted Linear Regression</td>\n",
       "      <td>382</td>\n",
       "      <td>151</td>\n",
       "      <td>108</td>\n",
       "      <td>433</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>534</td>\n",
       "      <td>134</td>\n",
       "      <td>133</td>\n",
       "      <td>364</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>507</td>\n",
       "      <td>241</td>\n",
       "      <td>282</td>\n",
       "      <td>387</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>450</td>\n",
       "      <td>160</td>\n",
       "      <td>207</td>\n",
       "      <td>266</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>354</td>\n",
       "      <td>135</td>\n",
       "      <td>158</td>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   19   20   21   22  total\n",
       "0  Restricted Linear Regression  382  151  108  433    433\n",
       "1             Linear Regression  534  134  133  364    534\n",
       "2                 Decision tree  507  241  282  387    507\n",
       "3                 Random forest  450  160  207  266    450\n",
       "4                       XGBoost  354  135  158  368    368"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = initialize_cv_split(df, X, y)\n",
    "\n",
    "reslinreg_data = reslinreg(params)\n",
    "linreg_data = linreg(params)\n",
    "tree_data, max_depth_best, min_leaf_samples_leaf = best_tree(params)\n",
    "forest_data = best_forest(params, max_depth_best)\n",
    "xgb_data = best_xgb(params, max_depth_best)\n",
    "\n",
    "data ={}\n",
    "col_names = ['Name', 19, 20, 21, 22, 'total']\n",
    "\n",
    "data = [['Restricted Linear Regression'] + reslinreg_data, \n",
    "        ['Linear Regression'] + linreg_data, ['Decision tree'] + tree_data, \n",
    "        ['Random forest'] + forest_data, ['XGBoost'] + xgb_data]\n",
    "\n",
    "models = pd.DataFrame(data, columns = col_names)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8817375",
   "metadata": {},
   "source": [
    "Okay, we see that the above functions reproduce what we got in Basic_models.ipynb. Now let's transform our data a bit and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72505f05",
   "metadata": {},
   "source": [
    "### 2. % $\\to$ Percentile $\\to$ % mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255c52e",
   "metadata": {},
   "source": [
    "Let's now try to map our data from percentages to percentiles, since they seem to be more informative than normal percentages, e.g. they include the information that the results usually are really ''dense'' around the score of 40%. \n",
    "\n",
    "Since our aim is to finally output percentages, this is what we'll do:\n",
    "\n",
    "On each training, we hide one of the years of data, map our training data (i.e. everything but one year) according to the distribution, which is the sum of the distributions of exams from these 3 training years (unfortunately, we don't have any other info about distributions except for the final exams), map the training data into percentiles, then find the best models to output desired percentiles and then finally map the percentiles back to the percentage scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe453e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputting exam distribution data\n",
    "\n",
    "data = {}\n",
    "sum_ = {}\n",
    "exam = {}\n",
    "\n",
    "data[19] = np.array([0.15, 0.9, 2.3, 3.9, 4.95, 5.4, 5.25, 5, 4.8, 4.55, 4.5, 4.25, 4.1, 3.9, 3.75, 3.6, 3.45, 3.25, 3.15, 3.1,\n",
    "                2.95, 2.8, 2.7, 2.65, 2.55, 2.45, 2.3, 2.1, 1.85, 1.6, 1.35])\n",
    "data[20] = np.array([0.05, 0.3, 1.1, 2.35, 3.7, 4.8, 5.4, 5.7, 5.55, 5.25, 5, 4.7, 4.5, 4.3, 4.1, 4, 3.8, 3.6, 3.5, 3.4, 3.2, 3.05,\n",
    "                    2.95, 2.7, 2.5, 2.3, 2.1, 1.9, 1.65, 1.1, 1.35])\n",
    "data[21] = np.array([0.1, 0.6, 2, 4.1, 6.1, 6.9, 6.7, 6.15, 5.45, 5.15, 4.95, 4.75, 4.55, 4.3, 4.15, 3.95, 3.75, 3.6, 3.35, 3.3, 3.05, 2.9, 2.8, 2.65, 2.55, 2.3])\n",
    "data[22] = np.array([0.15, 0.75, 2, 3.5, 4.5, 4.8, 4.6, 4.3, 3.95, 3.7, 3.55, 3.45, 3.4, 3.3, 3.25, 3.35, 3.45, 3.5, 3.7, 3.95, 4.35, 4.75, 5.45, 6.2, 6.8, 5.35])\n",
    "\n",
    "for year in range(19,23):\n",
    "    sum_[year] = np.sum(data[year])\n",
    "    data[year] = data[year]  / sum_[year]\n",
    "    exam[year] = {'perc': data[year]}\n",
    "    exam[year] = pd.DataFrame(exam[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df948a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data that simulates our distributions\n",
    "sim_data, sim_data_slice = {}, {} #\n",
    "for year in range(19,23):\n",
    "    sim_data[year] = []\n",
    "    for i in range(len(data[year])):\n",
    "        for j in range(int(1000 * data[year][i] + 0.01)):\n",
    "            sim_data[year].append(i/(len(data[year])-1))\n",
    "            \n",
    "# Data that simulates ''slice'' distributions, i.e. joint distributions of all years but one.\n",
    "for year in range(19,23):\n",
    "    sim_data_slice[year] = []\n",
    "    for yr in range(19,23):\n",
    "        if yr != year:\n",
    "            sim_data_slice[year] += sim_data[yr]\n",
    "    sim_data_slice[year].sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15853ddd",
   "metadata": {},
   "source": [
    "Now that we have our data simulation, one important note. We want to transform our data percentages into percentiles differently for our train set and dev set.\n",
    "\n",
    "Namely, when it comes to our training data (X_slice/X_slice_trimmed), we want it to be mapped to percentiles using distributions from the years of our training data, whereas our dev data (X_yr/X_yr_trimmed) should be mapped using distributions of all years but the year of our dev data (otherwise, we would pass it unknown informations about the general distributions of the year that we want to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b389570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping data to percentiles\n",
    "\n",
    "# Getting the usual data\n",
    "params = initialize_cv_split(df, X, y)\n",
    "\n",
    "X_yr, y_yr = params['X_yr'], params['y_yr'] \n",
    "X_slice, y_slice = params['X_slice'], params['y_slice'] \n",
    "X_slice_trimmed, X_yr_trimmed = params['X_slice_trimmed'], params['X_yr_trimmed'] \n",
    "X_slice_scaled, X_yr_scaled, X_slice_trimmed_scaled, X_yr_trimmed_scaled = \\\n",
    "params['X_slice_scaled'], params['X_yr_scaled'], params['X_slice_trimmed_scaled'], params['X_yr_trimmed_scaled']\n",
    "\n",
    "# Changing training data according to their distributions.\n",
    "X_slice_perc, X_yr_perc = {}, {} #Percentile analogues of the data above\n",
    "y_slice_perc, y_yr_perc = {}, {}\n",
    "X_slice_trimmed_perc, X_yr_trimmed_perc = {}, {} #Percentile analogues of the data above\n",
    "X_slice_scaled_perc, X_yr_scaled_perc, X_slice_trimmed_scaled_perc, X_yr_trimmed_scaled_perc = {}, {}, {}, {} \n",
    "\n",
    "X_yr_true_perc = {} \n",
    "#Percentiles of scores for the given year mapped using this years distribution, these will form building blocks for X_slice\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for year in range(19,23):\n",
    "    X_yr_perc[year], X_yr_true_perc[year] = X_yr[year].copy(), X_yr[year].copy()\n",
    "    y_yr_perc[year], y_slice_perc[year] = y_yr[year].copy(), y_slice[year].copy()\n",
    "    for col in X.columns:\n",
    "        # Making percentile versions of X_yr and X_slice\n",
    "        X_yr_perc[year][col] = stats.percentileofscore(sim_data_slice[year], X_yr_perc[year][col] / 100)\n",
    "        X_yr_true_perc[year][col] = stats.percentileofscore(sim_data[year], X_yr_true_perc[year][col] / 100)\n",
    "\n",
    "X_true_perc = pd.concat([X_yr_true_perc[19], X_yr_true_perc[20], X_yr_true_perc[21], X_yr_true_perc[22]], ignore_index=True)\n",
    "\n",
    "for year in range(19,23):\n",
    "    X_slice_perc[year] = X_true_perc[df['rocznik'] != year]\n",
    "        \n",
    "for year in range(19,23):\n",
    "    #Making percentile versions of y_yr and y_slice\n",
    "    y_yr_perc[year] = stats.percentileofscore(sim_data[year], y_yr_perc[year] / 100)\n",
    "    y_slice_perc[year] = stats.percentileofscore(sim_data_slice[year], y_slice_perc[year] / 100)\n",
    "        \n",
    "    # Making percentile versions of X_yr_trimmed, X_slice_trimmed\n",
    "    X_yr_trimmed_perc[year] = X_yr_perc[year].iloc[:,[0,4,5]]\n",
    "    X_slice_trimmed_perc[year] = X_slice_perc[year].iloc[:,[0,4,5]]\n",
    "\n",
    "    # Making percentile versions of X_..._scaled\n",
    "    X_slice_scaled_perc[year] = scaler.fit_transform(X_slice_perc[year])\n",
    "    X_yr_scaled_perc[year] = scaler.transform(X_yr_perc[year])\n",
    "    X_slice_trimmed_scaled_perc[year] = scaler.fit_transform(X_slice_trimmed_perc[year])\n",
    "    X_yr_trimmed_scaled_perc[year] = scaler.transform(X_yr_trimmed_perc[year])\n",
    "        \n",
    "params['X_slice'], params['X_yr'] = X_slice_perc, X_yr_perc \n",
    "params['X_slice_trimmed'], params['X_yr_trimmed'] = X_slice_trimmed_perc, X_yr_trimmed_perc\n",
    "params['X_slice_scaled'], params['X_yr_scaled'], params['X_slice_trimmed_scaled'], params['X_yr_trimmed_scaled'] = \\\n",
    "X_slice_scaled_perc, X_yr_scaled_perc, X_slice_trimmed_scaled_perc, X_yr_trimmed_scaled_perc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e503374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max depth for tree: 4\n",
      "Best min_samples_leaf for tree: 3\n",
      "\n",
      "Best max depth for forest: 1\n",
      "Best number of estimators: 2\n",
      "\n",
      "Best max depth for XGBoost: 1\n",
      "Best number of estimators: 19\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>747</td>\n",
       "      <td>217</td>\n",
       "      <td>254</td>\n",
       "      <td>674</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>567</td>\n",
       "      <td>334</td>\n",
       "      <td>339</td>\n",
       "      <td>749</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>569</td>\n",
       "      <td>195</td>\n",
       "      <td>193</td>\n",
       "      <td>692</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>513</td>\n",
       "      <td>187</td>\n",
       "      <td>144</td>\n",
       "      <td>520</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name   19   20   21   22  total\n",
       "0  Linear Regression  747  217  254  674    747\n",
       "1      Decision tree  567  334  339  749    749\n",
       "2      Random forest  569  195  193  692    692\n",
       "3            XGBoost  513  187  144  520    520"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing our models against percentile scores\n",
    "\n",
    "linreg_data = linreg(params, y_yr_true =  params['y_yr'].copy(), type_ = 'perc', distr = sim_data_slice)\n",
    "tree_data, max_depth_best, _ = best_tree(params, y_yr_true =  params['y_yr'].copy(), type_ = 'perc', distr = sim_data_slice)\n",
    "forest_data = best_forest(params, y_yr_true =  params['y_yr'].copy(), type_ = 'perc', distr = sim_data_slice)\n",
    "xgb_data = best_xgb(params, y_yr_true =  params['y_yr'].copy(), type_ = 'perc', distr = sim_data_slice)\n",
    "\n",
    "data_perc ={}\n",
    "col_names = ['Name', 19, 20, 21, 22, 'total']\n",
    "\n",
    "data_perc = [['Linear Regression'] + linreg_data, ['Decision tree'] + tree_data, \n",
    "        ['Random forest'] + forest_data, ['XGBoost'] + xgb_data]\n",
    "\n",
    "models_perc = pd.DataFrame(data_perc, columns = col_names)\n",
    "models_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d79ce85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the data to the main notebook\n",
    "\n",
    "models_perc.to_excel('score_perc_score.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d06c8",
   "metadata": {},
   "source": [
    "### 3. Percentile $\\to$ percentile mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d039409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max depth for tree: 5\n",
      "Best min_samples_leaf for tree: 3\n",
      "\n",
      "Best max depth for forest: 1\n",
      "Best number of estimators: 2\n",
      "\n",
      "Best max depth for XGBoost: 1\n",
      "Best number of estimators: 8\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Restricted Linear Regression</td>\n",
       "      <td>761</td>\n",
       "      <td>174</td>\n",
       "      <td>196</td>\n",
       "      <td>396</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>739</td>\n",
       "      <td>228</td>\n",
       "      <td>272</td>\n",
       "      <td>360</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>635</td>\n",
       "      <td>369</td>\n",
       "      <td>313</td>\n",
       "      <td>442</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>579</td>\n",
       "      <td>188</td>\n",
       "      <td>194</td>\n",
       "      <td>395</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>409</td>\n",
       "      <td>158</td>\n",
       "      <td>164</td>\n",
       "      <td>415</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   19   20   21   22  total\n",
       "0  Restricted Linear Regression  761  174  196  396    761\n",
       "1             Linear Regression  739  228  272  360    739\n",
       "2                 Decision tree  635  369  313  442    635\n",
       "3                 Random forest  579  188  194  395    579\n",
       "4                       XGBoost  409  158  164  415    415"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reslinreg_data = reslinreg(params)\n",
    "linreg_data = linreg(params)\n",
    "tree_data, max_depth_best, _ = best_tree(params)\n",
    "forest_data = best_forest(params)\n",
    "xgb_data = best_xgb(params)\n",
    "\n",
    "data2 ={}\n",
    "col_names = ['Name', 19, 20, 21, 22, 'total']\n",
    "\n",
    "data2 = [['Restricted Linear Regression'] + reslinreg_data, \n",
    "        ['Linear Regression'] + linreg_data, ['Decision tree'] + tree_data, \n",
    "        ['Random forest'] + forest_data, ['XGBoost'] + xgb_data]\n",
    "\n",
    "models2 = pd.DataFrame(data2, columns = col_names)\n",
    "\n",
    "models2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d7aa1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the data to the main notebook\n",
    "\n",
    "models2.to_excel('perc_to_perc.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05a5709",
   "metadata": {},
   "source": [
    "### 4. Data augmentation - making ''shadows'' of students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf69714a",
   "metadata": {},
   "source": [
    "Note that in the normal model scores $\\to$ scores, we don't really take into account the information that we have about the distributions of the exams. \n",
    "But how could we possibly include in our dataset/training the information about the distribution other than by scores $\\to$ percentile mapping as before?\n",
    "\n",
    "Well, we can augment additional data, by creating a ''shadow'' of each student, i.e. for student $A$ make an instance of student $A'$ so that for each test if $A$ scored $s$ points getting to $p$-th percentile, $A'$ ''scored'' $s'$ points, \n",
    "which places them on $100-p$-th percentile.\n",
    "\n",
    "Let's try this idea below but this time, since we are not in the need of percentile mapping of our dev set, let's make each X_slice percentile mapped purely by the distribution of their final exam distribution, not the sum of the three years that are in the slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d26c08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping df into percentiles according to end exams results.\n",
    "\n",
    "df_yr, df_perc_yr = {}, {}\n",
    "for year in range(19,23):\n",
    "    df_yr[year] = df[df['rocznik'] == year]\n",
    "\n",
    "for year in range(19,23):\n",
    "    df_perc_yr[year] = df_yr[year].copy()\n",
    "    for col in df_yr[year].columns[1:]:\n",
    "        df_perc_yr[year][col] = stats.percentileofscore(sim_data[year], df_perc_yr[year][col] / 100)\n",
    "        \n",
    "df_perc = pd.concat([df_perc_yr[19], df_perc_yr[20], df_perc_yr[21], df_perc_yr[22]], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd28ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rocznik</th>\n",
       "      <th>sesja I</th>\n",
       "      <th>X</th>\n",
       "      <th>XII</th>\n",
       "      <th>sesja II</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>wynik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>77.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>85.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>41.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>78.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rocznik  sesja I     X   XII  sesja II    II   III  wynik\n",
       "0       19     77.0  53.0  63.0      75.0  75.0  61.0     60\n",
       "1       19     85.0  69.0  97.0      93.0  91.0  88.0     93\n",
       "2       19     41.0  31.0  33.0      48.0  66.0  36.0     50\n",
       "3       19     78.0  81.0  83.0      70.0  94.0  91.0     93\n",
       "4       19     26.0  22.0  53.0      25.0  41.0  21.0     27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rocznik</th>\n",
       "      <th>sesja I</th>\n",
       "      <th>X</th>\n",
       "      <th>XII</th>\n",
       "      <th>sesja II</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>wynik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>56.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rocznik    sesja I          X        XII   sesja II         II        III  \\\n",
       "0       19  16.666667  33.333333  26.666667  16.666667  16.666667  26.666667   \n",
       "1       19  13.333333  20.000000   6.666667  10.000000  10.000000  10.000000   \n",
       "2       19  40.000000  53.333333  53.333333  33.333333  23.333333  46.666667   \n",
       "3       19  16.666667  13.333333  13.333333  20.000000   6.666667  10.000000   \n",
       "4       19  63.333333  66.666667  33.333333  63.333333  40.000000  66.666667   \n",
       "\n",
       "       wynik  \n",
       "0  26.666667  \n",
       "1  10.000000  \n",
       "2  33.333333  \n",
       "3  10.000000  \n",
       "4  56.666667  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making ''inverses'' of students\n",
    "df_perc_inv = df_perc.copy()\n",
    "df_perc_inv.iloc[:,1:] = 100 - df_perc_inv.iloc[:,1:]\n",
    "\n",
    "# Mapping ''inverses'' into scores\n",
    "df_perc_inv_yr, df_inv_yr = {}, {}\n",
    "for year in range(19,23):\n",
    "    df_perc_inv_yr[year] = df_perc_inv[df_perc_inv['rocznik'] == year]\n",
    "    \n",
    "for year in range(19,23):\n",
    "    df_inv_yr[year] = df_perc_inv_yr[year].copy()\n",
    "    for col in df_perc_inv_yr[year].columns[1:]:\n",
    "        df_inv_yr[year][col] = 100 * stats.scoreatpercentile(sim_data[year], df_perc_inv_yr[year][col])\n",
    "\n",
    "df_inv = pd.concat([df_inv_yr[19], df_inv_yr[20], df_inv_yr[21], df_inv_yr[22]], ignore_index = True)\n",
    "\n",
    "display(df.head())\n",
    "df_inv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb3ce07",
   "metadata": {},
   "source": [
    "Ok, let's now test it on our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc1490cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max depth for tree: 3\n",
      "Best min_samples_leaf for tree: 3\n",
      "\n",
      "Best max depth for forest: 1\n",
      "Best number of estimators: 17\n",
      "\n",
      "Best max depth for XGBoost: 1\n",
      "Best number of estimators: 19\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Restricted Linear Regression</td>\n",
       "      <td>669</td>\n",
       "      <td>238</td>\n",
       "      <td>441</td>\n",
       "      <td>139</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>366</td>\n",
       "      <td>288</td>\n",
       "      <td>249</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>483</td>\n",
       "      <td>394</td>\n",
       "      <td>447</td>\n",
       "      <td>562</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>264</td>\n",
       "      <td>494</td>\n",
       "      <td>239</td>\n",
       "      <td>438</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>246</td>\n",
       "      <td>348</td>\n",
       "      <td>215</td>\n",
       "      <td>334</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   19   20   21   22  total\n",
       "0  Restricted Linear Regression  669  238  441  139    669\n",
       "1             Linear Regression  366  288  249  488    488\n",
       "2                 Decision tree  483  394  447  562    562\n",
       "3                 Random forest  264  494  239  438    494\n",
       "4                       XGBoost  246  348  215  334    348"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = initialize_cv_split(df, X, y)\n",
    "\n",
    "# Why didn't we pass df_inv to initialize_cv_split? We want df_inv only to be in our training set but not in dev set\n",
    "scaler = StandardScaler()\n",
    "for year in range(19,23):\n",
    "    params['X_slice'][year] = pd.concat([params['X_slice'][year], \n",
    "                                         df_inv[df_inv['rocznik'] != year].iloc[:,1:-1]], ignore_index= True)\n",
    "    params['y_slice'][year] = pd.concat([params['y_slice'][year], \n",
    "                                         df_inv[df_inv['rocznik'] != year]['wynik']], ignore_index= True)\n",
    "    \n",
    "    params['X_slice_trimmed'][year], params['X_yr_trimmed'][year] = \\\n",
    "    params['X_slice'][year].iloc[:,[0,4,5]], params['X_yr'][year].iloc[:,[0,4,5]]\n",
    "    \n",
    "    #scaling normal data\n",
    "    params['X_slice_scaled'][year] = scaler.fit_transform(params['X_slice'][year])\n",
    "    params['X_yr_scaled'][year] = scaler.transform(params['X_yr'][year])\n",
    "\n",
    "    #scaling trimmed versions\n",
    "    params['X_slice_trimmed_scaled'][year] = scaler.fit_transform(params['X_slice_trimmed'][year])\n",
    "    params['X_yr_trimmed_scaled'][year] = scaler.transform(params['X_yr_trimmed'][year])\n",
    "\n",
    "\n",
    "reslinreg_data = reslinreg(params)\n",
    "linreg_data = linreg(params)\n",
    "tree_data, max_depth_best, min_samples_leaf_best = best_tree(params)\n",
    "forest_data = best_forest(params)\n",
    "xgb_data = best_xgb(params)\n",
    "\n",
    "data ={}\n",
    "col_names = ['Name', 19, 20, 21, 22, 'total']\n",
    "\n",
    "data_aug = [['Restricted Linear Regression'] + reslinreg_data, \n",
    "        ['Linear Regression'] + linreg_data, ['Decision tree'] + tree_data, \n",
    "        ['Random forest'] + forest_data, ['XGBoost'] + xgb_data]\n",
    "\n",
    "models_aug = pd.DataFrame(data_aug, columns = col_names)\n",
    "\n",
    "models_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a4b43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the data to the main notebook\n",
    "\n",
    "models_aug.to_excel('model_aug.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c5a57f",
   "metadata": {},
   "source": [
    "### 5. More data augmentation - making \"translations\" of students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c5d09",
   "metadata": {},
   "source": [
    "As described in the write-up, now instead of making \"shadows\" of students, we will make their translations, i.e. \n",
    "having set fixed $\\hat{p}$ we take each students scores, map them to percentiles $p$ (based on the year's \n",
    "exam distributions), translate them to percentiles $p+\\hat{p}$ and then back to scores.\n",
    "\n",
    "Details: we will just consider $\\hat{p}\\in\\{-60,-40,\\ldots, 40,60\\}$ and \n",
    "translate the student's percentiles only if they don't fall out of bounds ([0,100]).\n",
    "On one hand, this will make different number of copies of each students but note that this way we \n",
    "give smaller \"weight\" to the students that have big variance of results and hence are hard to cope with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b78137a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping our data to percentiles and splitting into separate years.\n",
    "# Mapping df into percentiles according to end exams results.\n",
    "\n",
    "df_yr, df_trans_yr = {}, {}\n",
    "for year in range(19,23):\n",
    "    df_yr[year] = df[df['rocznik'] == year]\n",
    "\n",
    "for year in range(19,23):\n",
    "    df_trans_yr[year] = df_yr[year].copy()\n",
    "    for col in df_yr[year].columns[1:]:\n",
    "        df_trans_yr[year][col] = stats.percentileofscore(sim_data[year], df_trans_yr[year][col] / 100)\n",
    "\n",
    "for year in range(19,20):\n",
    "    for p_hat in np.arange(-20, 21, 20):\n",
    "        if p_hat != 0:\n",
    "            df_trans_temp = df_trans_yr[year].copy()\n",
    "            df_trans_temp.iloc[:,1:] = df_trans_temp.iloc[:,1:] + p_hat\n",
    "\n",
    "            # Adding min and max columns\n",
    "            min_ = np.min(df_trans_temp.iloc[:,1:], axis = 1)\n",
    "            df_trans_temp['min'] = min_\n",
    "            max_ = np.max(df_trans_temp.iloc[:,1:], axis = 1)\n",
    "            df_trans_temp['max'] = max_\n",
    "\n",
    "            # Checking out-of-boundedness\n",
    "            df_trans_temp = df_trans_temp[df_trans_temp['min'] > 0]\n",
    "            df_trans_temp = df_trans_temp[df_trans_temp['max'] < 100]\n",
    "            df_trans_temp = df_trans_temp.drop(columns = ['min', 'max'])\n",
    "\n",
    "            # Mapping back\n",
    "            for col in df_trans_temp.columns[1:]:\n",
    "                df_trans_temp[col] = 100 * stats.scoreatpercentile(sim_data[year], df_trans_temp[col])\n",
    "\n",
    "            #Adding df_trans_temp to df_trans_yr\n",
    "            df_trans_yr[year] = pd.concat([df_trans_yr[year], df_trans_temp], ignore_index=True)\n",
    "        \n",
    "# Making a complete DataFrame out of it\n",
    "df_trans = pd.concat([df_trans_yr[19], df_trans_yr[20], df_trans_yr[21], df_trans_yr[22]], ignore_index=True)\n",
    "df_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c850fa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max depth for tree: 4\n",
      "Best min_samples_leaf for tree: 3\n",
      "\n",
      "Best max depth for forest: 1\n",
      "Best number of estimators: 2\n",
      "\n",
      "Best max depth for XGBoost: 1\n",
      "Best number of estimators: 9\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Restricted Linear Regression</td>\n",
       "      <td>444</td>\n",
       "      <td>147</td>\n",
       "      <td>109</td>\n",
       "      <td>477</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>522</td>\n",
       "      <td>144</td>\n",
       "      <td>130</td>\n",
       "      <td>432</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>489</td>\n",
       "      <td>404</td>\n",
       "      <td>200</td>\n",
       "      <td>448</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>446</td>\n",
       "      <td>118</td>\n",
       "      <td>168</td>\n",
       "      <td>276</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>367</td>\n",
       "      <td>121</td>\n",
       "      <td>140</td>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   19   20   21   22  total\n",
       "0  Restricted Linear Regression  444  147  109  477    477\n",
       "1             Linear Regression  522  144  130  432    522\n",
       "2                 Decision tree  489  404  200  448    489\n",
       "3                 Random forest  446  118  168  276    446\n",
       "4                       XGBoost  367  121  140  369    369"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = initialize_cv_split(df, X, y)\n",
    "\n",
    "# Why didn't we pass df_inv to initialize_cv_split? We want df_inv only to be in our training set but not in dev set\n",
    "scaler = StandardScaler()\n",
    "for year in range(19,23):\n",
    "    params['X_slice'][year] = pd.concat([params['X_slice'][year], \n",
    "                                         df_trans[df_trans['rocznik'] != year].iloc[:,1:-1]], ignore_index= True)\n",
    "    params['y_slice'][year] = pd.concat([params['y_slice'][year], \n",
    "                                         df_trans[df_trans['rocznik'] != year]['wynik']], ignore_index= True)\n",
    "    \n",
    "    params['X_slice_trimmed'][year], params['X_yr_trimmed'][year] = \\\n",
    "    params['X_slice'][year].iloc[:,[0,4,5]], params['X_yr'][year].iloc[:,[0,4,5]]\n",
    "    \n",
    "    #scaling normal data\n",
    "    params['X_slice_scaled'][year] = scaler.fit_transform(params['X_slice'][year])\n",
    "    params['X_yr_scaled'][year] = scaler.transform(params['X_yr'][year])\n",
    "\n",
    "    #scaling trimmed versions\n",
    "    params['X_slice_trimmed_scaled'][year] = scaler.fit_transform(params['X_slice_trimmed'][year])\n",
    "    params['X_yr_trimmed_scaled'][year] = scaler.transform(params['X_yr_trimmed'][year])\n",
    "\n",
    "\n",
    "reslinreg_data = reslinreg(params)\n",
    "linreg_data = linreg(params)\n",
    "tree_data, max_depth_best, _ = best_tree(params)\n",
    "forest_data = best_forest(params)\n",
    "xgb_data = best_xgb(params)\n",
    "\n",
    "data ={}\n",
    "col_names = ['Name', 19, 20, 21, 22, 'total']\n",
    "\n",
    "data_trans = [['Restricted Linear Regression'] + reslinreg_data, \n",
    "        ['Linear Regression'] + linreg_data, ['Decision tree'] + tree_data, \n",
    "        ['Random forest'] + forest_data, ['XGBoost'] + xgb_data]\n",
    "\n",
    "models_trans = pd.DataFrame(data_trans, columns = col_names)\n",
    "\n",
    "models_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f90da31",
   "metadata": {},
   "source": [
    "(By hand inspection, out of ranges np.arange(-20, 21, 20), np.arange(-40, 41, 20), np.arange(-60, 61, 20), np.arange(-80, 81, 20), the best is the first one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b849d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the data to the main notebook\n",
    "\n",
    "models_trans.to_excel('models_trans.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334bd390",
   "metadata": {},
   "source": [
    "### 7. Shadows and translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de914120",
   "metadata": {},
   "source": [
    "Essentially, it suffices to pass our \"translations\" dataframe into \"shadows\" code and we should be done. Here we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01f6a7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping our data to percentiles and splitting into separate years.\n",
    "# Mapping df into percentiles according to end exams results.\n",
    "\n",
    "df_yr, df_trans_yr = {}, {}\n",
    "for year in range(19,23):\n",
    "    df_yr[year] = df[df['rocznik'] == year]\n",
    "\n",
    "for year in range(19,23):\n",
    "    df_trans_yr[year] = df_yr[year].copy()\n",
    "    for col in df_yr[year].columns[1:]:\n",
    "        df_trans_yr[year][col] = stats.percentileofscore(sim_data[year], df_trans_yr[year][col] / 100)\n",
    "\n",
    "for year in range(19,20):\n",
    "    for p_hat in np.arange(-20, 21, 20):\n",
    "        if p_hat != 0:\n",
    "            df_trans_temp = df_trans_yr[year].copy()\n",
    "            df_trans_temp.iloc[:,1:] = df_trans_temp.iloc[:,1:] + p_hat\n",
    "\n",
    "            # Adding min and max columns\n",
    "            min_ = np.min(df_trans_temp.iloc[:,1:], axis = 1)\n",
    "            df_trans_temp['min'] = min_\n",
    "            max_ = np.max(df_trans_temp.iloc[:,1:], axis = 1)\n",
    "            df_trans_temp['max'] = max_\n",
    "\n",
    "            # Checking out-of-boundedness\n",
    "            df_trans_temp = df_trans_temp[df_trans_temp['min'] > 0]\n",
    "            df_trans_temp = df_trans_temp[df_trans_temp['max'] < 100]\n",
    "            df_trans_temp = df_trans_temp.drop(columns = ['min', 'max'])\n",
    "\n",
    "            # Mapping back\n",
    "            for col in df_trans_temp.columns[1:]:\n",
    "                df_trans_temp[col] = 100 * stats.scoreatpercentile(sim_data[year], df_trans_temp[col])\n",
    "\n",
    "            #Adding df_trans_temp to df_trans_yr\n",
    "            df_trans_yr[year] = pd.concat([df_trans_yr[year], df_trans_temp], ignore_index=True)\n",
    "        \n",
    "# Making a complete DataFrame out of it\n",
    "df_trans = pd.concat([df_trans_yr[19], df_trans_yr[20], df_trans_yr[21], df_trans_yr[22]], ignore_index=True)\n",
    "X_trans = df_trans.iloc[:,1:-1]\n",
    "y_trans = df_trans['wynik']\n",
    "\n",
    "df_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3672b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping df into percentiles according to end exams results.\n",
    "df_trans\n",
    "df_trans_yr, df_trans_perc_yr = {}, {}\n",
    "for year in range(19,23):\n",
    "    df_trans_yr[year] = df_trans[df_trans['rocznik'] == year]\n",
    "\n",
    "for year in range(19,23):\n",
    "    df_trans_perc_yr[year] = df_trans_yr[year].copy()\n",
    "    for col in df_trans_yr[year].columns[1:]:\n",
    "        df_trans_perc_yr[year][col] = stats.percentileofscore(sim_data[year], df_trans_perc_yr[year][col] / 100)\n",
    "        \n",
    "df_trans_perc = pd.concat([df_trans_perc_yr[19], df_trans_perc_yr[20], \n",
    "                           df_trans_perc_yr[21], df_trans_perc_yr[22]], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55c0f835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making ''inverses'' of students\n",
    "df_trans_perc_inv = df_trans_perc.copy()\n",
    "df_trans_perc_inv.iloc[:,1:] = 100 - df_trans_perc_inv.iloc[:,1:]\n",
    "\n",
    "# Mapping ''inverses'' into scores\n",
    "df_trans_perc_inv_yr, df_trans_inv_yr = {}, {}\n",
    "for year in range(19,23):\n",
    "    df_trans_perc_inv_yr[year] = df_trans_perc_inv[df_trans_perc_inv['rocznik'] == year]\n",
    "    \n",
    "for year in range(19,23):\n",
    "    df_trans_inv_yr[year] = df_trans_perc_inv_yr[year].copy()\n",
    "    for col in df_trans_perc_inv_yr[year].columns[1:]:\n",
    "        df_trans_inv_yr[year][col] = 100 * stats.scoreatpercentile(sim_data[year], df_trans_perc_inv_yr[year][col])\n",
    "\n",
    "df_trans_inv = pd.concat([df_trans_inv_yr[19], df_trans_inv_yr[20], \n",
    "                          df_trans_inv_yr[21], df_trans_inv_yr[22]], ignore_index = True)\n",
    "\n",
    "display(df_trans_inv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f41f2402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max depth for tree: 2\n",
      "Best min_samples_leaf for tree: 3\n",
      "\n",
      "Best max depth for forest: 1\n",
      "Best number of estimators: 2\n",
      "\n",
      "Best max depth for XGBoost: 1\n",
      "Best number of estimators: 20\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Restricted Linear Regression</td>\n",
       "      <td>750</td>\n",
       "      <td>309</td>\n",
       "      <td>224</td>\n",
       "      <td>347</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>347</td>\n",
       "      <td>280</td>\n",
       "      <td>244</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>360</td>\n",
       "      <td>308</td>\n",
       "      <td>229</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>437</td>\n",
       "      <td>436</td>\n",
       "      <td>450</td>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>212</td>\n",
       "      <td>233</td>\n",
       "      <td>120</td>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   19   20   21   22  total\n",
       "0  Restricted Linear Regression  750  309  224  347    750\n",
       "1             Linear Regression  347  280  244  486    486\n",
       "2                 Decision tree  360  308  229  407    407\n",
       "3                 Random forest  437  436  450  534    534\n",
       "4                       XGBoost  212  233  120  368    368"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = initialize_cv_split(df, X, y)\n",
    "\n",
    "# Why didn't we pass df_inv to initialize_cv_split? We want df_inv only to be in our training set but not in dev set\n",
    "scaler = StandardScaler()\n",
    "for year in range(19,23):\n",
    "    params['X_slice'][year] = pd.concat([params['X_slice'][year], \n",
    "                                         df_trans[df_trans['rocznik'] != year].iloc[:,1:-1]], ignore_index= True)\n",
    "    params['X_slice'][year] = pd.concat([params['X_slice'][year], \n",
    "                                         df_trans_inv[df_trans_inv['rocznik'] != year].iloc[:,1:-1]], ignore_index= True)\n",
    "    params['y_slice'][year] = pd.concat([params['y_slice'][year], \n",
    "                                         df_trans[df_trans['rocznik'] != year]['wynik']], ignore_index= True)\n",
    "    params['y_slice'][year] = pd.concat([params['y_slice'][year], \n",
    "                                         df_trans_inv[df_trans_inv['rocznik'] != year]['wynik']], ignore_index= True)\n",
    "    \n",
    "    params['X_slice_trimmed'][year], params['X_yr_trimmed'][year] = \\\n",
    "    params['X_slice'][year].iloc[:,[0,4,5]], params['X_yr'][year].iloc[:,[0,4,5]]\n",
    "    \n",
    "    #scaling normal data\n",
    "    params['X_slice_scaled'][year] = scaler.fit_transform(params['X_slice'][year])\n",
    "    params['X_yr_scaled'][year] = scaler.transform(params['X_yr'][year])\n",
    "\n",
    "    #scaling trimmed versions\n",
    "    params['X_slice_trimmed_scaled'][year] = scaler.fit_transform(params['X_slice_trimmed'][year])\n",
    "    params['X_yr_trimmed_scaled'][year] = scaler.transform(params['X_yr_trimmed'][year])\n",
    "\n",
    "\n",
    "reslinreg_data = reslinreg(params)\n",
    "linreg_data = linreg(params)\n",
    "tree_data, max_depth_best, _ = best_tree(params)\n",
    "forest_data = best_forest(params)\n",
    "xgb_data = best_xgb(params)\n",
    "\n",
    "data ={}\n",
    "col_names = ['Name', 19, 20, 21, 22, 'total']\n",
    "\n",
    "data_trans_aug = [['Restricted Linear Regression'] + reslinreg_data, \n",
    "        ['Linear Regression'] + linreg_data, ['Decision tree'] + tree_data, \n",
    "        ['Random forest'] + forest_data, ['XGBoost'] + xgb_data]\n",
    "\n",
    "model_trans_aug = pd.DataFrame(data_trans_aug, columns = col_names)\n",
    "\n",
    "model_trans_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19db7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the data to the main notebook\n",
    "\n",
    "model_trans_aug.to_excel('model_trans_aug.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626180c6",
   "metadata": {},
   "source": [
    "### 8. Best model mean mae error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05917a",
   "metadata": {},
   "source": [
    "Here is mae of the best model, i.e. XGBoost of depth = 1 and n_estimators = 19 with augmented data by adding percentile inverses of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3b37463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max depth for XGBoost: 1\n",
      "Best number of estimators: 19\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>12.113492</td>\n",
       "      <td>13.636335</td>\n",
       "      <td>12.022682</td>\n",
       "      <td>15.499053</td>\n",
       "      <td>13.317891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name         19         20         21         22      total\n",
       "0  XGBoost  12.113492  13.636335  12.022682  15.499053  13.317891"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = initialize_cv_split(df, X, y)\n",
    "\n",
    "# Why didn't we pass df_inv to initialize_cv_split? We want df_inv only to be in our training set but not in dev set\n",
    "scaler = StandardScaler()\n",
    "for year in range(19,23):\n",
    "    params['X_slice'][year] = pd.concat([params['X_slice'][year], \n",
    "                                         df_inv[df_inv['rocznik'] != year].iloc[:,1:-1]], ignore_index= True)\n",
    "    params['y_slice'][year] = pd.concat([params['y_slice'][year], \n",
    "                                         df_inv[df_inv['rocznik'] != year]['wynik']], ignore_index= True)\n",
    "    \n",
    "    params['X_slice_trimmed'][year], params['X_yr_trimmed'][year] = \\\n",
    "    params['X_slice'][year].iloc[:,[0,4,5]], params['X_yr'][year].iloc[:,[0,4,5]]\n",
    "    \n",
    "    #scaling normal data\n",
    "    params['X_slice_scaled'][year] = scaler.fit_transform(params['X_slice'][year])\n",
    "    params['X_yr_scaled'][year] = scaler.transform(params['X_yr'][year])\n",
    "\n",
    "    #scaling trimmed versions\n",
    "    params['X_slice_trimmed_scaled'][year] = scaler.fit_transform(params['X_slice_trimmed'][year])\n",
    "    params['X_yr_trimmed_scaled'][year] = scaler.transform(params['X_yr_trimmed'][year])\n",
    "\n",
    "xgb_data = best_xgb(params, mode = 'mae')\n",
    "\n",
    "data ={}\n",
    "col_names = ['Name', 19, 20, 21, 22, 'total']\n",
    "\n",
    "data_aug = [['XGBoost'] + xgb_data]\n",
    "\n",
    "models_aug_mae = pd.DataFrame(data_aug, columns = col_names)\n",
    "\n",
    "models_aug_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aae4b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_aug_mae.to_excel('models_aug_mae.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
